The Autograph Album was worked on from 1853-1875 and was kept and owned by FÃ©lix Nadar in France. This book is held at the University of Pennsylvania, Kislak Center for Special Collectiions, Rare Books and Manuscripts, University of Pennsylvania Libraries Special Collections, Ms. Coll. 21.

Colenda Entry: https://colenda.library.upenn.edu/catalog/81431-p3w08x23m
Catalogue Entry: https://find.library.upenn.edu/catalog/9913857533503681?hld_id=resource_link_0

In the metadata, I chose to record the file name and the ID link to the data in the JSON file to make it easier to return to the original material and keep data well-organized. As this book is an autograph album, I chose to record the names of the signers on each page. As each signature represents a celebrated artist, ranging from poets to painters, who visited Nadar in his studio, I thought it would be important to record their full names and their occupations as artists. Additionally, I recorded the years they lived and when they approximately signed the book, as these details make up the background of the signatures preserved in the autograph album. I also recorded the language/nationality of the artists but since Nadar was located in France, a majority of the signatures are by French artists who predominantly wrote in French. Finally, I categorized the page's details/drawings to describe what the artists illustrated in the book beyond just their own signature. These categories included poems and scores of music. 



For extracting and cleaning the test, I mostly used Transkribus as my book is a manuscript that mostly contains handwritten passages. Once I uploaded the pages to the program, I used the Notaire de la Nouvelle-France, a French model, to transcribe the handwritten words. I decided against training my own model because my book is an autograph album with hundreds of different artists working on each page, so I believed it would be difficult for the model to be trained to a specific handwriting as there were various. Although I'm curious if it would be possible to have the model learn what type of writing patterns were popular in the era it was completed. The model I used did a decent job of extracting the text; however it did come up with a lot of errors, especially with the signatures, which had to be corrected. This is expected as many of the signatures had unique flourishes that couldn't be seen clearly. Additionally, I had a hard time finding errors as the language was in French, which I'm not fluent in at all. The model also had a hard time picking up sentences and paragraphs when they were written out horizontally instead of just vertically. As of now, I think humans will have to continue to have a very significant role in looking into the transcribed data and assisting models. I think it's important that humans continue to play a monitoring role in extracting and cleaning text that way they can make sound judgments in enhancements and corrections that preserve the reality of the source material.